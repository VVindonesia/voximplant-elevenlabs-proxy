require('dotenv').config();
const express = require('express');
const axios = require('axios');
const fs = require('fs');
const path = require('path');
const cors = require('cors');
const helmet = require('helmet');
const { exec } = require('child_process');

const app = express();
const PORT = process.env.PORT || 3000;

// Middleware
app.use(helmet());
app.use(cors());
app.use(express.json());
app.use('/audio', express.static('public'));

// –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤
if (!fs.existsSync('public')) {
    fs.mkdirSync('public');
}

// Edge TTS endpoint (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π Microsoft TTS)
app.post('/tts/edge', async (req, res) => {
    try {
        const { text, voice = 'en-US-AriaNeural', rate = '0%', pitch = '0Hz' } = req.body;
        
        if (!text) {
            return res.status(400).json({ error: 'Text is required' });
        }

        console.log('Generating speech with Edge TTS...');
        
        // –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        const filename = `tts_edge_${Date.now()}_${Math.random().toString(36).substr(2, 9)}.mp3`;
        const filepath = path.join(__dirname, 'public', filename);
        
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º edge-tts –∫–æ–º–∞–Ω–¥—É
        const command = `echo "${text.replace(/"/g, '\\"')}" | edge-tts --voice "${voice}" --rate="${rate}" --pitch="${pitch}" --write-media "${filepath}"`;
        
        await new Promise((resolve, reject) => {
            exec(command, (error, stdout, stderr) => {
                if (error) {
                    console.error('Edge TTS Error:', error);
                    reject(error);
                } else {
                    resolve();
                }
            });
        });

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–ª—Å—è
        if (!fs.existsSync(filepath)) {
            throw new Error('Failed to generate audio file');
        }

        // –í–æ–∑–≤—Ä–∞—â–∞–µ–º URL
        const audioUrl = `https://${req.get('host')}/audio/${filename}`;
        
        res.json({ 
            success: true,
            url: audioUrl,
            filename: filename,
            provider: 'edge-tts'
        });

        // –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª —á–µ—Ä–µ–∑ 10 –º–∏–Ω—É—Ç
        setTimeout(() => {
            fs.unlink(filepath, (err) => {
                if (err) console.error('Error deleting file:', err);
            });
        }, 10 * 60 * 1000);

    } catch (error) {
        console.error('Edge TTS Error:', error);
        res.status(500).json({ 
            error: 'Edge TTS generation failed',
            details: error.message
        });
    }
});

// OpenAI TTS endpoint
app.post('/tts/openai', async (req, res) => {
    try {
        const { text, voice = 'alloy', model = 'tts-1' } = req.body;
        
        if (!text) {
            return res.status(400).json({ error: 'Text is required' });
        }

        if (!process.env.OPENAI_API_KEY) {
            return res.status(500).json({ error: 'OPENAI_API_KEY not configured' });
        }

        console.log('Making request to OpenAI TTS...');
        
        const response = await axios({
            method: 'POST',
            url: 'https://api.openai.com/v1/audio/speech',
            headers: {
                'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
                'Content-Type': 'application/json'
            },
            data: {
                model: model,
                input: text,
                voice: voice,
                response_format: 'mp3'
            },
            responseType: 'arraybuffer',
            timeout: 30000
        });

        const filename = `tts_openai_${Date.now()}_${Math.random().toString(36).substr(2, 9)}.mp3`;
        const filepath = path.join(__dirname, 'public', filename);
        
        fs.writeFileSync(filepath, response.data);

        const audioUrl = `https://${req.get('host')}/audio/${filename}`;
        
        res.json({ 
            success: true,
            url: audioUrl,
            filename: filename,
            provider: 'openai'
        });

        setTimeout(() => {
            fs.unlink(filepath, (err) => {
                if (err) console.error('Error deleting file:', err);
            });
        }, 10 * 60 * 1000);

    } catch (error) {
        console.error('OpenAI TTS Error:', error.response?.data || error.message);
        res.status(500).json({ 
            error: 'OpenAI TTS generation failed',
            details: error.response?.data || error.message
        });
    }
});

// ElevenLabs TTS endpoint
app.post('/tts/elevenlabs', async (req, res) => {
    try {
        const { text, voice_id = 'pNInz6obpgDQGcFmaJgB' } = req.body;
        
        if (!text) {
            return res.status(400).json({ error: 'Text is required' });
        }

        if (!process.env.ELEVEN_API_KEY) {
            return res.status(500).json({ error: 'ELEVEN_API_KEY not configured' });
        }

        console.log('Making request to Eleven Labs directly...');

        // –ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –∫ Eleven Labs API —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
        const response = await axios({
            method: 'POST',
            url: `https://api.elevenlabs.io/v1/text-to-speech/${voice_id}`,
            headers: {
                'Accept': 'audio/mpeg',
                'Content-Type': 'application/json',
                'xi-api-key': process.env.ELEVEN_API_KEY,
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Origin': 'https://elevenlabs.io',
                'Referer': 'https://elevenlabs.io/'
            },
            data: {
                text: text,
                model_id: 'eleven_monolingual_v1',
                voice_settings: {
                    stability: 0.5,
                    similarity_boost: 0.5
                }
            },
            responseType: 'arraybuffer',
            timeout: 30000,
            // –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–∫—Å–∏ –∏ –¥—Ä—É–≥–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
            validateStatus: function (status) {
                return status < 500; // –ü—Ä–∏–Ω–∏–º–∞–µ–º –ª—é–±—ã–µ –∫–æ–¥—ã –∫—Ä–æ–º–µ —Å–µ—Ä–≤–µ—Ä–Ω—ã—Ö –æ—à–∏–±–æ–∫
            }
        });

        if (response.status !== 200) {
            throw new Error(`ElevenLabs returned ${response.status}: ${response.statusText}`);
        }

        const filename = `tts_eleven_${Date.now()}_${Math.random().toString(36).substr(2, 9)}.mp3`;
        const filepath = path.join(__dirname, 'public', filename);
        
        fs.writeFileSync(filepath, response.data);

        const audioUrl = `https://${req.get('host')}/audio/${filename}`;
        
        res.json({ 
            success: true,
            url: audioUrl,
            filename: filename,
            provider: 'elevenlabs'
        });

        setTimeout(() => {
            fs.unlink(filepath, (err) => {
                if (err) console.error('Error deleting file:', err);
            });
        }, 10 * 60 * 1000);

    } catch (error) {
        console.error('ElevenLabs TTS Error:', error.response?.data || error.message);
        console.error('ElevenLabs Full Error:', error);
        
        // –ï—Å–ª–∏ ElevenLabs –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø—Ä–æ–±—É–µ–º —Ñ–∞–ª–ª–±–µ–∫ –Ω–∞ Edge TTS
        console.log('ElevenLabs failed, falling back to Edge TTS...');
        return await edgeTTSHandler(req, res);
    }
});

// –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô TTS ENDPOINT - –û–°–ù–û–í–ù–û–ô –¥–ª—è Voximplant
app.post('/tts', async (req, res) => {
    const { text, provider = 'elevenlabs', voice } = req.body; // ElevenLabs –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    if (!text) {
        return res.status(400).json({ error: 'Text is required' });
    }

    // –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: ElevenLabs > Edge TTS > OpenAI
    let selectedProvider = provider;
    if (provider === 'auto') {
        selectedProvider = 'elevenlabs';  // ElevenLabs –∫–∞–∫ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
    }

    console.log(`üéØ Trying TTS provider: ${selectedProvider}`);
    console.log(`üìù Text to synthesize: "${text}"`);

    try {
        if (selectedProvider === 'elevenlabs' && process.env.ELEVEN_API_KEY) {
            console.log('üéµ Using ElevenLabs TTS');
            return await elevenLabsTTSHandler(req, res);
        } else if (selectedProvider === 'edge') {
            console.log('üéµ Using Edge TTS');
            return await edgeTTSHandler(req, res);
        } else if (selectedProvider === 'openai' && process.env.OPENAI_API_KEY) {
            console.log('üéµ Using OpenAI TTS');
            return await openaiTTSHandler(req, res);
        } else {
            console.log('‚ùå No valid TTS provider available');
            return res.status(400).json({ error: 'No valid TTS provider available' });
        }
    } catch (error) {
        console.error('‚ùå TTS routing error:', error);
        res.status(500).json({ error: 'TTS routing failed', details: error.message });
    }
});

// –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
async function edgeTTSHandler(req, res) {
    const { text, voice = 'ru-RU-SvetlanaNeural' } = req.body; // –†—É—Å—Å–∫–∏–π –≥–æ–ª–æ—Å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    try {
        console.log('üîä Edge TTS: Generating audio...');
        const filename = `tts_edge_${Date.now()}_${Math.random().toString(36).substr(2, 9)}.mp3`;
        const filepath = path.join(__dirname, 'public', filename);
        
        const command = `echo "${text.replace(/"/g, '\\"')}" | edge-tts --voice "${voice}" --write-media "${filepath}"`;
        
        await new Promise((resolve, reject) => {
            exec(command, (error) => {
                if (error) {
                    console.error('Edge TTS exec error:', error);
                    reject(error);
                } else {
                    resolve();
                }
            });
        });

        if (!fs.existsSync(filepath)) {
            throw new Error('Failed to generate audio file with Edge TTS');
        }

        const audioUrl = `https://${req.get('host')}/audio/${filename}`;
        
        console.log('‚úÖ Edge TTS: Audio generated successfully');
        res.json({ 
            success: true,
            url: audioUrl,
            filename: filename,
            provider: 'edge-tts'
        });

        setTimeout(() => {
            fs.unlink(filepath, (err) => {
                if (err) console.error('Error deleting file:', err);
            });
        }, 10 * 60 * 1000);

    } catch (error) {
        console.error('‚ùå Edge TTS Handler Error:', error);
        throw error;
    }
}

async function elevenLabsTTSHandler(req, res) {
    try {
        const { text, voice_id = 'pNInz6obpgDQGcFmaJgB' } = req.body;
        
        if (!text) {
            throw new Error('Text is required');
        }

        if (!process.env.ELEVEN_API_KEY) {
            throw new Error('ELEVEN_API_KEY not configured');
        }

        console.log('üéµ ElevenLabs: Making API request...');
        console.log(`üéµ ElevenLabs: Using voice_id: ${voice_id}`);

        const response = await axios({
            method: 'POST',
            url: `https://api.elevenlabs.io/v1/text-to-speech/${voice_id}`,
            headers: {
                'Accept': 'audio/mpeg',
                'Content-Type': 'application/json',
                'xi-api-key': process.env.ELEVEN_API_KEY,
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Origin': 'https://elevenlabs.io',
                'Referer': 'https://elevenlabs.io/'
            },
            data: {
                text: text,
                model_id: 'eleven_monolingual_v1',
                voice_settings: {
                    stability: 0.5,
                    similarity_boost: 0.5
                }
            },
            responseType: 'arraybuffer',
            timeout: 30000,
            validateStatus: function (status) {
                return status < 500;
            }
        });

        if (response.status !== 200) {
            throw new Error(`ElevenLabs API returned ${response.status}: ${response.statusText}`);
        }

        const filename = `tts_eleven_${Date.now()}_${Math.random().toString(36).substr(2, 9)}.mp3`;
        const filepath = path.join(__dirname, 'public', filename);
        
        fs.writeFileSync(filepath, response.data);

        const audioUrl = `https://${req.get('host')}/audio/${filename}`;
        
        console.log('‚úÖ ElevenLabs: Audio generated successfully');
        res.json({ 
            success: true,
            url: audioUrl,
            filename: filename,
            provider: 'elevenlabs'
        });

        setTimeout(() => {
            fs.unlink(filepath, (err) => {
                if (err) console.error('Error deleting file:', err);
            });
        }, 10 * 60 * 1000);

    } catch (error) {
        console.error('‚ùå ElevenLabs Handler Error:', error.response?.data || error.message);
        
        // –§–∞–ª–ª–±–µ–∫ –Ω–∞ Edge TTS
        console.log('üîÑ ElevenLabs failed, trying Edge TTS fallback...');
        return await edgeTTSHandler(req, res);
    }
}

async function openaiTTSHandler(req, res) {
    const { text, voice = 'alloy', model = 'tts-1' } = req.body;
    
    try {
        if (!process.env.OPENAI_API_KEY) {
            throw new Error('OPENAI_API_KEY not configured');
        }

        console.log('üéµ OpenAI: Making TTS request...');
        
        const response = await axios({
            method: 'POST',
            url: 'https://api.openai.com/v1/audio/speech',
            headers: {
                'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
                'Content-Type': 'application/json'
            },
            data: {
                model: model,
                input: text,
                voice: voice,
                response_format: 'mp3'
            },
            responseType: 'arraybuffer',
            timeout: 30000
        });

        const filename = `tts_openai_${Date.now()}_${Math.random().toString(36).substr(2, 9)}.mp3`;
        const filepath = path.join(__dirname, 'public', filename);
        
        fs.writeFileSync(filepath, response.data);

        const audioUrl = `https://${req.get('host')}/audio/${filename}`;
        
        console.log('‚úÖ OpenAI: Audio generated successfully');
        res.json({ 
            success: true,
            url: audioUrl,
            filename: filename,
            provider: 'openai'
        });

        setTimeout(() => {
            fs.unlink(filepath, (err) => {
                if (err) console.error('Error deleting file:', err);
            });
        }, 10 * 60 * 1000);

    } catch (error) {
        console.error('‚ùå OpenAI Handler Error:', error.response?.data || error.message);
        throw error;
    }
}

// Health check
app.get('/health', (req, res) => {
    const providers = ['edge-tts']; // Edge TTS –≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω
    if (process.env.OPENAI_API_KEY) providers.push('openai');
    if (process.env.ELEVEN_API_KEY) providers.push('elevenlabs');
    
    res.json({ 
        status: 'OK', 
        timestamp: new Date().toISOString(),
        providers: providers,
        default: 'elevenlabs', // –¢–µ–ø–µ—Ä—å ElevenLabs –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        region: 'auto-detect'
    });
});

// –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≥–æ–ª–æ—Å–æ–≤
app.get('/voices', (req, res) => {
    const voices = {
        'edge-tts': [
            { id: 'ru-RU-SvetlanaNeural', name: 'Svetlana (Russian)', gender: 'female' },
            { id: 'ru-RU-DmitryNeural', name: 'Dmitry (Russian)', gender: 'male' },
            { id: 'en-US-AriaNeural', name: 'Aria (English US)', gender: 'female' },
            { id: 'en-US-JennyNeural', name: 'Jenny (English US)', gender: 'female' },
            { id: 'en-US-GuyNeural', name: 'Guy (English US)', gender: 'male' }
        ],
        openai: [
            { id: 'alloy', name: 'Alloy', gender: 'neutral' },
            { id: 'echo', name: 'Echo', gender: 'male' },
            { id: 'fable', name: 'Fable', gender: 'male' },
            { id: 'onyx', name: 'Onyx', gender: 'male' },
            { id: 'nova', name: 'Nova', gender: 'female' },
            { id: 'shimmer', name: 'Shimmer', gender: 'female' }
        ],
        elevenlabs: [
            { id: 'pNInz6obpgDQGcFmaJgB', name: 'Adam', gender: 'male' },
            { id: 'EXAVITQu4vr4xnSDxMaL', name: 'Bella', gender: 'female' },
            { id: 'VR6AewLTigWG4xSOukaG', name: 'Antoni', gender: 'male' },
            { id: 'TxGEqnHWrfWFTfGW9XjX', name: 'Josh', gender: 'male' }
        ]
    };
    
    res.json(voices);
});

// Chat endpoint –¥–ª—è AI –æ—Ç–≤–µ—Ç–æ–≤
app.post('/chat', async (req, res) => {
    try {
        const { messages } = req.body;
        
        if (!process.env.GROQ_API_KEY) {
            return res.status(500).json({ error: 'GROQ_API_KEY not configured' });
        }

        console.log('ü§ñ Groq: Making chat request...');
        
        const response = await axios({
            method: 'POST',
            url: 'https://api.groq.com/openai/v1/chat/completions',
            headers: {
                'Authorization': `Bearer ${process.env.GROQ_API_KEY}`,
                'Content-Type': 'application/json'
            },
            data: {
                model: 'llama-3.1-8b-instant',
                messages: messages,
                max_tokens: 150,
                temperature: 0.7
            }
        });
        
        console.log('‚úÖ Groq: Response received');
        res.json(response.data);
    } catch (error) {
        console.error('‚ùå Groq Chat Error:', error.response?.data || error.message);
        res.status(500).json({ error: error.message });
    }
});

// –¢–µ—Å—Ç–æ–≤—ã–π endpoint –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ ElevenLabs
app.get('/test-elevenlabs', async (req, res) => {
    try {
        const testResponse = await axios({
            method: 'GET',
            url: 'https://api.elevenlabs.io/v1/voices',
            headers: {
                'xi-api-key': process.env.ELEVEN_API_KEY
            }
        });
        
        res.json({
            status: 'ElevenLabs API is accessible',
            voices_count: testResponse.data.voices?.length || 0
        });
    } catch (error) {
        res.json({
            status: 'ElevenLabs API error',
            error: error.response?.data || error.message,
            suggestion: 'Check API key or regional restrictions'
        });
    }
});

app.listen(PORT, () => {
    console.log(`üöÄ TTS Proxy server running on port ${PORT}`);
    console.log('üìã Available providers:');
    console.log('   - ElevenLabs TTS (PRIMARY)');
    console.log('   - Edge TTS (Microsoft) - FREE FALLBACK');
    if (process.env.OPENAI_API_KEY) console.log('   - OpenAI TTS');
    if (process.env.GROQ_API_KEY) console.log('   - Groq AI Chat');
    console.log('üåê Test endpoints:');
    console.log(`   - Health: https://voximplant-elevenlabs-proxy.onrender.com/health`);
    console.log(`   - Test ElevenLabs: https://voximplant-elevenlabs-proxy.onrender.com/test-elevenlabs`);
});
